{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is for making the demo / video grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import json\n",
    "from torch import Tensor\n",
    "from jaxtyping import Float, UInt8\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.image as mpimg\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an image grid for ground truth, pixelsplat, instructir and controlnet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img_grid(real_dir, gen_dir, output_dir):\n",
    "    \n",
    "    for key_dir in tqdm(gen_dir.iterdir(), desc='Processing directories'):\n",
    "\n",
    "        if not key_dir.suffix.lower() == '.json':\n",
    "            key = key_dir.stem\n",
    "            output_path = Path(output_dir + f\"/{key}\")\n",
    "            output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            for i, _ in enumerate((key_dir / Path(\"color\")).iterdir()):\n",
    "\n",
    "                gen_img_path = key_dir / Path(\"color\") / Path(f\"{i:06d}.png\")\n",
    "                real_img_path = Path(real_dir) / Path(key) / Path(\"target\") / Path(f\"{i:06d}.png\")\n",
    "                inst_img_path = Path(real_dir) / Path(key) / Path(\"instructir\") / Path(f\"{i:06d}.png\")                \n",
    "                cont_img_path = Path(real_dir) / Path(key) / Path(\"controlnet\") / Path(f\"{i:06d}.png\")\n",
    "\n",
    "                fig, axes = plt.subplots(1, 4, figsize=(10, 5)) \n",
    "\n",
    "                # Display real image\n",
    "                real_img = mpimg.imread(real_img_path)\n",
    "                axes[0].imshow(real_img)\n",
    "                axes[0].axis('off') \n",
    "                axes[0].set_title('Ground Truth')\n",
    "\n",
    "                # Display generated image from pixelsplat\n",
    "                gen_img = mpimg.imread(gen_img_path)\n",
    "                axes[1].imshow(gen_img)\n",
    "                axes[1].axis('off')  \n",
    "                axes[1].set_title('pixelSplat') \n",
    "\n",
    "                # Display generated image from InstructIR\n",
    "                inst_img = mpimg.imread(inst_img_path)\n",
    "                axes[2].imshow(inst_img)\n",
    "                axes[2].axis('off')  \n",
    "                axes[2].set_title('InstructIR')\n",
    "\n",
    "                # Display generated image from ControlNet\n",
    "                cont_img = mpimg.imread(cont_img_path)\n",
    "                axes[3].imshow(cont_img)\n",
    "                axes[3].axis('off')  \n",
    "                axes[3].set_title('ControlNet')\n",
    "\n",
    "                plt.subplots_adjust(wspace=0.05)\n",
    "                plt.savefig(output_path / Path(f\"{str(i)}.png\"), bbox_inches='tight')\n",
    "                plt.close(fig)\n",
    "\n",
    "            # break for testing for just one room\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dir = Path('../outputs/re10k_test_hard/re10k')\n",
    "gen_root = Path('../outputs/re10k_test_hard/re10k')\n",
    "output_dir = \"../outputs/re10k_img_grid\"\n",
    "\n",
    "make_img_grid(gen_root, gen_root, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a video out of the image grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(path_imgs, output_path, framerate=30):\n",
    "    for room in Path(path_imgs).iterdir():  \n",
    "        key = room.stem\n",
    "        output_dir = Path(output_path)\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        img_array = []\n",
    "        i = 0\n",
    "        for _ in (Path(path_imgs)/Path(key)).iterdir():\n",
    "            filename = path_imgs + \"/\" + key + f\"/{i}.png\"\n",
    "            img = cv2.imread(filename)\n",
    "            height, width, _ = img.shape\n",
    "            size = (width,height)\n",
    "            img_array.append(img)\n",
    "            i += 1\n",
    "\n",
    "        out = cv2.VideoWriter(f'{output_path}/{key}.avi',cv2.VideoWriter_fourcc(*'DIVX'), framerate, size)\n",
    "\n",
    "        for i in range(len(img_array)):\n",
    "            out.write(img_array[i])\n",
    "\n",
    "        out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_imgs = \"../outputs/re10k_img_grid\"\n",
    "output_path = \"../outputs/re10k_video_grid\"\n",
    "\n",
    "create_video(path_imgs, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images from torch files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is to generate grid videos for ground truth images from torch files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories of the real data\n",
    "video_index_path = \"../assets/evaluation_index_re10k_video.json\"\n",
    "root = Path('../datasets/re10k')\n",
    "data_stages = [\"test\"]\n",
    "\n",
    "# Directories of the generated data such that the folders within are the room keys\n",
    "gen_root = Path('../outputs/re10k_test_hard_more/re10k')\n",
    "\n",
    "# number of videos you want to produce\n",
    "num_vid = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_index = {}\n",
    "path_to_torch = []\n",
    "\n",
    "for data_stage in data_stages:\n",
    "    with (root / data_stage / \"index.json\").open(\"r\") as f:\n",
    "        index = json.load(f)    \n",
    "    for k, v in index.items():\n",
    "        path = Path(root / data_stage / v)\n",
    "        index[k] = path\n",
    "        if path not in path_to_torch:\n",
    "            path_to_torch.append(path)\n",
    "\n",
    "    assert not (set(merged_index.keys()) & set(index.keys()))\n",
    "\n",
    "    merged_index = {**merged_index, **index}\n",
    "\n",
    "print(merged_index)\n",
    "print(f\"#rooms: {len(merged_index.keys())}\")\n",
    "print(path_to_torch)\n",
    "print(f\"#torch files: {len(path_to_torch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.ToTensor()\n",
    "\n",
    "def convert_images(images: list[UInt8[Tensor, \"...\"]],) -> Float[Tensor, \"batch 3 height width\"]:\n",
    "    torch_images = []\n",
    "    for image in images:\n",
    "        image = Image.open(BytesIO(image.numpy().tobytes()))\n",
    "        torch_images.append(tensor(image))\n",
    "    return torch.stack(torch_images)\n",
    "\n",
    "def center_crop(\n",
    "    images: Float[Tensor, \"*#batch c h w\"],\n",
    "    shape: tuple[int, int],\n",
    ") -> tuple[\n",
    "    Float[Tensor, \"*#batch c h_out w_out\"],  # updated images\n",
    "]:\n",
    "    *_, h_in, w_in = images.shape\n",
    "    h_out, w_out = shape\n",
    "    \n",
    "    # Note that odd input dimensions induce half-pixel misalignments.\n",
    "    row = (h_in - h_out) // 2\n",
    "    col = (w_in - w_out) // 2\n",
    "\n",
    "    # Center-crop the image.\n",
    "    images = images[..., :, row : row + h_out, col : col + w_out]\n",
    "\n",
    "    return images\n",
    "\n",
    "def save_images(path_to_torch, out_dir):\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    n = 0\n",
    "\n",
    "    keys = []\n",
    "\n",
    "    for path in path_to_torch:\n",
    "        chunk = torch.load(path)\n",
    "        for room in tqdm(chunk, desc=\"Processing rooms\", unit=\"room\"):\n",
    "\n",
    "            print(f\"n: {n}\")\n",
    "\n",
    "            if n >= num_vid:\n",
    "                break\n",
    "\n",
    "            key = room[\"key\"]\n",
    "            keys.append(key)\n",
    "            print(key)\n",
    "\n",
    "            images = room[\"images\"]\n",
    "            context_images = convert_images(images)\n",
    "\n",
    "            room_path = out_dir / Path(key)\n",
    "            room_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            for i, image in enumerate(context_images):\n",
    "                # img = center_crop(image, (256, 256))\n",
    "                img = center_crop(image, (360, 360))\n",
    "                # break\n",
    "                image_array = img.permute(1, 2, 0).numpy()\n",
    "                image_array = (image_array * 255).astype('uint8')\n",
    "                plt.imsave(f'{room_path}/{i}.png', image_array)\n",
    "            \n",
    "            n += 1\n",
    "\n",
    "        if n >= num_vid:\n",
    "            break\n",
    "        # break\n",
    "    # break\n",
    "\n",
    "    return keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = save_images(path_to_torch, \"/home/rooshutter/Documents/Master/CV2/project/diffusion-augmented-pixelsplat/outputs/re10k_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
